{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenCV version\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for image processing, visualization, and analysis\n",
    "#from skimage.data import cells3d\n",
    "from pathlib import Path\n",
    "#import ndimage\n",
    "\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import statistics as st\n",
    "import xlsxwriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import pyvista as pv\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import dilation, square\n",
    "from skimage.segmentation import find_boundaries\n",
    "from itertools import combinations\n",
    "\n",
    "from skimage import io, filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import EllipseModel\n",
    "from vispy.color import Colormap\n",
    "from tabulate import tabulate\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.colors import to_rgb, to_hex\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D, Config3D, StarDist3D\n",
    "from stardist.data import test_image_nuclei_2d\n",
    "from stardist.plot import render_label\n",
    "\n",
    "from IPython.display import display_html, clear_output\n",
    "\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "from napari.settings import get_settings\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528e5d3-4be6-4c08-bd1a-521791c65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma correction function\n",
    "def gamma_trans(im_in,gamma):\n",
    "    val_c = 255.0 / (np.max(im_in)**gamma)\n",
    "    im_out = val_c*(im_in**gamma)\n",
    "    return im_out.copy()\n",
    "\n",
    "# Contrast stretching/limiting function\n",
    "def contr_limit(im_in,c_min,c_max):\n",
    "    alpha = 255.0/(c_max - c_min)\n",
    "    beta = - c_min * (alpha)\n",
    "    im_out=(np.clip(alpha*im_in+beta, 0.0, 255.0)).astype(int)\n",
    "    #print(np.max(im_out))\n",
    "    return im_out.copy()\n",
    "\n",
    "# Plot histogram and cumulative distribution for each channel\n",
    "def hist_plot(im_in,stain_complete_df,thresh=0):\n",
    "\n",
    "    fig, axs = plt.subplots(1,im_in.shape[2],figsize=(15,2))\n",
    "\n",
    "    for z in range(0,im_in.shape[2]):\n",
    "        hist,bins = np.histogram(im_in[:,:,z].flatten(),256,[0,256])\n",
    "        \n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf* hist.max()/ cdf.max()\n",
    "    \n",
    "        color=stain_complete_df.loc[stain_complete_df.index[z],'Color']\n",
    "    \n",
    "        axs[z].plot(cdf_normalized, color = 'b')\n",
    "        if color=='white':\n",
    "            axs[z].hist(im_in[:,:,z].flatten(),256,[0,256], color = 'gray')\n",
    "        else:\n",
    "            axs[z].hist(im_in[:,:,z].flatten(),256,[0,256], color = color)\n",
    "        axs[z].set_xlim([0,256])\n",
    "        axs[z].legend(('cdf','histogram'), loc = 'upper left')\n",
    "        if thresh>0:\n",
    "            axs[c].plot([thresh,thresh],[0,cdf_normalized.max()],color='g')\n",
    "        axs[z].set_title(stain_complete_df.index[z])\n",
    "        axs[z].set_yscale('log')\n",
    "\n",
    "# Truncate long values for display in tables\n",
    "def truncate_cell(val, width=15):\n",
    "    val_str = str(val)\n",
    "    return val_str if len(val_str) <= width else val_str[:width-3] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc6b12-fdff-4c9e-a8df-a933ca94380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge touching labels in a label matrix using adjacency and union-find\n",
    "def merge_touching_labels(label_matrix):\n",
    "    # Get max label\n",
    "    max_label = label_matrix.max()\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    adjacency = np.zeros((max_label + 1, max_label + 1), dtype=bool)\n",
    "    \n",
    "    # Pad to avoid boundary issues\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Check for touching labels\n",
    "    for i in range(1, padded.shape[0]-1):\n",
    "        for j in range(1, padded.shape[1]-1):\n",
    "            center = padded[i, j]\n",
    "            if center == 0:\n",
    "                continue\n",
    "            neighborhood = padded[i-1:i+2, j-1:j+2].ravel()\n",
    "            for neighbor in neighborhood:\n",
    "                if neighbor != center and neighbor != 0:\n",
    "                    adjacency[center, neighbor] = True\n",
    "                    adjacency[neighbor, center] = True\n",
    "    \n",
    "    # Union-Find to group connected labels\n",
    "    parent = list(range(max_label + 1))\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    for i in range(1, max_label + 1):\n",
    "        for j in range(1, max_label + 1):\n",
    "            if adjacency[i, j]:\n",
    "                union(i, j)\n",
    "\n",
    "    # Map each label to its root\n",
    "    label_map = {i: find(i) for i in range(1, max_label + 1)}\n",
    "\n",
    "    # Create merged label matrix\n",
    "    merged = np.zeros_like(label_matrix)\n",
    "    for i in range(1, max_label + 1):\n",
    "        merged[label_matrix == i] = label_map[i]\n",
    "    \n",
    "    # Relabel to make sequential\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "## File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load TIFF file and extract image data\n",
    "tiff_file='PRO_EB_009_LD_2D.tif'\n",
    "meta=AICSImage(tiff_file)\n",
    "\n",
    "img = meta.get_image_data(\"XYZ\", T=0) \n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021b76a-2cee-40a6-a26b-f39fcbee5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get physical pixel sizes for X and Y axes\n",
    "r_X=meta.physical_pixel_sizes.X\n",
    "r_Y=meta.physical_pixel_sizes.Y\n",
    "print([r_X,r_Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stain dictionary: mapping condition to marker and color\n",
    "stain_dict={\n",
    "    'DEAD':['EthD','Red'],\n",
    "    'ALIVE':['Calcein AM','Green']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa53135-2a20-4ad4-863d-ede8c2ebf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all keys and values in stain_dict to uppercase for consistency\n",
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "\n",
    "# Create DataFrame from stain_dict\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Color'])\n",
    "stain_df.index.name='Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each channel in napari viewer\n",
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    im_in=meta.get_image_data(\"XY\", Z=c, C=0, S=0, T=0)\n",
    "    im_in=(im_in/256.0).astype('uint8')\n",
    "    \n",
    "    viewer_0.add_image(im_in, name=stain_df.index[c] + ' (' + c_name + ')', \n",
    "                        colormap=stain_df['Color'][c], blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for acquisition and contrast/gamma settings\n",
    "name_setup='PRO_EB-009'\n",
    "use_setup=True\n",
    "# stain_new_df=stain_complete_df.copy()\n",
    "\n",
    "stain_df=stain_df.reset_index(drop=False)\n",
    "stain_complete_df = stain_df.copy()\n",
    "stain_complete_df.set_index(['Condition', 'Marker','Color'], inplace=True)\n",
    "stain_complete_df[['Cont_min','Cont_max','Gamma']]=[0,255,1]\n",
    "\n",
    "# Try to load previous setup if available\n",
    "if use_setup and os.path.exists(name_setup + '_setup.csv'):\n",
    "    stain_setup_df = pd.read_csv(name_setup + '_setup.csv')\n",
    "    stain_setup_df.set_index(['Condition', 'Marker','Color'], inplace=True)\n",
    "    #print(tabulate(stain_setup_df, headers='keys', tablefmt='grid', showindex=True))\n",
    "    for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "        if stain_complete_df.index[c] in list(stain_setup_df.index.values):\n",
    "            stain_complete_df.loc[stain_complete_df.index[c]]=stain_setup_df.loc[stain_complete_df.index[c]]\n",
    "            # stain_new_df=stain_new_df.drop(stain_complete_df.index[c])\n",
    "        else:\n",
    "            use_setup=False\n",
    "\n",
    "# If no setup, allow user to adjust contrast/gamma interactively in napari\n",
    "if not(use_setup) or not(os.path.exists(name_setup + '_setup.csv')):\n",
    "\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    \n",
    "    for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "        im_in=meta.get_image_data(\"XY\", Z=c, C=0, S=0, T=0)\n",
    "        im_in=(im_in/256.0).astype('uint8')\n",
    "            \n",
    "        viewer_1.add_image(im_in, name=stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')', \n",
    "                            colormap=stain_complete_df.index[c][2],blending='additive')\n",
    "        \n",
    "    napari.run()\n",
    "    \n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    \n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "        stain_complete_df.loc[stain_complete_df.index[c], 'Cont_min'] =int(contrast_limits[stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')'][0])\n",
    "        stain_complete_df.loc[stain_complete_df.index[c], 'Cont_max'] =int(contrast_limits[stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')'][1])\n",
    "        stain_complete_df.loc[stain_complete_df.index[c], 'Gamma'] =gamma_val[stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')']\n",
    "\n",
    "    if os.path.exists(name_setup + '_setup.csv'):\n",
    "        stain_setup_df = pd.read_csv(name_setup + '_setup.csv')\n",
    "        stain_setup_df.set_index(['Condition', 'Marker','Color'], inplace=True)\n",
    "        for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "            stain_setup_df.loc[stain_complete_df.index[c]]=stain_complete_df.loc[stain_complete_df.index[c]]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df=stain_csv_setup_df[['Condition','Marker','Color','Cont_min','Cont_max','Gamma']]\n",
    "    stain_csv_setup_df.to_csv(name_setup + '_setup.csv', index=False)\n",
    "\n",
    "stain_df=stain_df.set_index('Condition')\n",
    "stain_complete_df=stain_complete_df.reset_index()\n",
    "stain_complete_df=stain_complete_df.set_index('Condition')\n",
    "stain_complete_df=stain_complete_df.loc[stain_df.index]\n",
    "\n",
    "stain_complete_df=stain_complete_df[['Marker','Color','Cont_min','Cont_max','Gamma']]\n",
    "    \n",
    "#print(tabulate(stain_complete_df, headers='keys', tablefmt='grid', showindex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ba932-3e34-4c20-91a2-8c3cf61d750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the complete stain setup DataFrame\n",
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "## MULTIPLE TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and initialize transformation variables\n",
    "im_in=meta.get_image_data(\"XYZ\", C=0, S=0, T=0)\n",
    "im_in=(im_in/256.0).astype('uint8')\n",
    "im_original=im_in.copy()\n",
    "im_out=im_in.copy()\n",
    "im_trans=im_out.copy()\n",
    "\n",
    "# Plot histogram for each channel\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal using median filter\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    im_out[:,:,z]=filters.median(im_in[:,:,z])\n",
    "\n",
    "im_denoised=im_out.copy()\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464bd2-a092-4e4b-a903-a76f22969c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter for smoothing\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    im_out[:,:,z]=filters.gaussian(im_in[:,:,z],1.0,preserve_range=True)\n",
    "\n",
    "im_filtered=im_out.copy()\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment for each channel\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "    im_out[:,:,c]=contr_limit(im_out[:,:,c],stain_complete_df.loc[stain_complete_df.index[c],'Cont_min'],stain_complete_df.loc[stain_complete_df.index[c],'Cont_max'])\n",
    "    im_out[:,:,c]=gamma_trans(im_out[:,:,c],stain_complete_df.loc[stain_complete_df.index[c],'Gamma'])\n",
    "\n",
    "im_trans=im_out.copy()\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6ca68-af3b-4ca6-8d08-cfe24a5444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding using Otsu's method for each channel\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):        \n",
    "    \n",
    "    #Threshold filter\n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    th_filter.SetInsideValue(0)\n",
    "    th_filter.SetOutsideValue(200)\n",
    "    \n",
    "    seg = th_filter.Execute(sitk.GetImageFromArray(im_in[:,:,z]))\n",
    "    \n",
    "    im_out[:,:,z]=sitk.GetArrayFromImage(seg)\n",
    "\n",
    "im_threshold=im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation using either StarDist or watershed\n",
    "im_in=im_out.copy()\n",
    "\n",
    "trig_stardist=False\n",
    "\n",
    "for z in range(0,im_in.shape[2]): \n",
    "    if trig_stardist:\n",
    "        # Use StarDist model for segmentation\n",
    "        model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "        img_te = normalize(im_trans[:,:,z],1.0,99.8)\n",
    "        im_out[:,:,z], _ = model.predict_instances(img_te)\n",
    "        im_mask=im_in[:,:,z]/np.max(im_in[:,:,z])\n",
    "        im_mask=ndi.binary_erosion(im_mask,structure=np.ones((2,2))).astype(im_mask.dtype)\n",
    "        im_positive=im_out*(im_mask)\n",
    "        list_positive=list(np.unique(im_positive))\n",
    "        list_positive=list_positive[1:]\n",
    "    else:\n",
    "        # Use watershed segmentation\n",
    "        distance = ndi.distance_transform_edt(im_in[:,:,z])\n",
    "        coords = peak_local_max(distance, footprint=np.ones((3,3)), labels=im_in[:,:,z].astype('uint8'))\n",
    "        mask = np.zeros(distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndi.label(mask)\n",
    "        im_out[:,:,z] = watershed(-distance, markers, mask=im_in[:,:,z])\n",
    "        im_out[:,:,z] = merge_touching_labels(im_out[:,:,z])\n",
    "\n",
    "\n",
    "cm_rand=np.random.rand(int(np.max(im_out)),3)\n",
    "cm_rand[0,:]=[0.0,0.0,0.0]\n",
    "colormaps_rand=Colormap(cm_rand)\n",
    "\n",
    "#im_out=labels.copy()\n",
    "im_segmented=im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all processing steps in napari viewer\n",
    "viewer_0 = napari.Viewer()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    viewer_0.add_image(im_original[:,:,z], name='ORIGINAL '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_denoised[:,:,z], name='DENOISED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_filtered[:,:,z], name='FILTERED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_trans[:,:,z], name='CORRECTED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_threshold[:,:,z], name='THRESHOLDED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_segmented[:,:,z], name='SEGMENTED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=colormaps_rand, blending='additive')\n",
    "\n",
    "viewer_0.scale_bar.visible=True\n",
    "viewer_0.scale_bar.unit='um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "## QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431e1f-94b5-4e66-aef5-accb0297f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify segmented objects and compute statistics\n",
    "im_mask=im_segmented>0\n",
    "labels_dict={}\n",
    "for i in range(0,im_in.shape[2]):\n",
    "    position_list = []\n",
    "    size_list=[]\n",
    "    marker = stain_df['Marker'][i]\n",
    "    for n in range(1, np.max(im_segmented[:,:,i])+1):\n",
    "        layer = stain_df.index.get_loc(stain_df.index[i])\n",
    "        y, x = np.where(im_segmented[:, :, layer] == n)\n",
    "        mx = np.mean(x * r_X)\n",
    "        my = np.mean(y * r_Y)\n",
    "        position_list.append((mx, my))\n",
    "        size_list.append(np.shape(x)[0]*r_X*r_Y)  \n",
    "    labels_dict[stain_complete_df['Marker'].iloc[i]]=[marker,stain_complete_df.index[i],np.max(im_segmented[:,:,i]),(),tuple(position_list),tuple(size_list)]\n",
    "\n",
    "# Compute all combinations of layers for overlap analysis\n",
    "layers_n = list(range(im_mask.shape[2]))\n",
    "all_combinations = []\n",
    "\n",
    "for k in range(2, len(layers_n) + 1):\n",
    "    all_combinations.extend(combinations(layers_n, k))\n",
    "\n",
    "for iter in all_combinations:\n",
    "    shared_mask=(im_mask[:,:,iter[0]] > 0) & (im_mask[:,:,iter[1]] > 0)\n",
    "    shared_labels=np.stack([im_segmented[shared_mask,iter[0]], im_segmented[shared_mask,iter[1]]], axis=1)\n",
    "    for j in range(3,np.size(iter)+1):\n",
    "        shared_mask=shared_mask & (im_mask[:,:,iter[j-1]] > 0)\n",
    "        shared_array=[]\n",
    "        for k in range(j):\n",
    "            shared_array=[shared_array,im_segmented[shared_mask,iter[k]]]\n",
    "        shared_labels=np.stack(shared_array, axis=1)\n",
    "    unique_shared_labels = np.unique(shared_labels, axis=0)  \n",
    "\n",
    "    position_list = []\n",
    "    size_list=[]\n",
    "    marker_t = iter[0]\n",
    "    for n in unique_shared_labels:\n",
    "        #layer = list(stain_df[stain_df['Marker'] == marker].reset_index(drop=True)['index'])[0]\n",
    "        y, x = np.where(im_segmented[:, :, marker_t] == n[0])\n",
    "        mx = np.mean(x * r_X)\n",
    "        my = np.mean(y * r_Y)\n",
    "        position_list.append((mx, my))\n",
    "        size_list.append(np.shape(x)[0]*r_X*r_Y)  \n",
    "    #labels_dict[stain_complete_df['Marker'].iloc[i]]=[marker,np.max(im_segmented[:,:,i]),(),position_list,size_list]\n",
    "\n",
    "    name_labels=[]\n",
    "    name_conditions=[]\n",
    "    for n in range(np.size(iter)):\n",
    "        name_labels.append(stain_complete_df['Marker'].iloc[n])\n",
    "        name_conditions.append(stain_complete_df.index[n])\n",
    "\n",
    "    # print(\"Overlapping label pairs (layer1_label, layer2_label):\")\n",
    "    # print(unique_shared_labels)\n",
    "    values_labels=[]\n",
    "    for n in range(np.size(unique_shared_labels[:,0])):\n",
    "        values_labels.append(tuple(unique_shared_labels[n]))\n",
    "\n",
    "    labels_dict[tuple(name_labels)]=[name_labels, name_conditions, np.size(unique_shared_labels[:,0]), tuple(values_labels),tuple(position_list),tuple(size_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5021b-f096-45e7-bd06-c5681ac18b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from quantification results and truncate long values for display\n",
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Marker','Condition','Number','Shared labels','Mean positions [um]','Cell size [um2]'])\n",
    "labels_df.index.name='Combination'\n",
    "\n",
    "# Make a copy with truncated cell values\n",
    "truncated_df = labels_df.copy()\n",
    "truncated_df[\"Shared labels\"] = truncated_df[\"Shared labels\"].apply(lambda x: truncate_cell(x))\n",
    "truncated_df[\"Mean positions [um]\"] = truncated_df[\"Mean positions [um]\"].apply(lambda x: truncate_cell(x))\n",
    "truncated_df[\"Cell size [um2]\"] = truncated_df[\"Cell size [um2]\"].apply(lambda x: truncate_cell(x))\n",
    "    \n",
    "#print(tabulate(truncated_df, headers='keys', tablefmt='grid', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db857798-416e-4885-a89e-ec09e95003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for cell counts and sizes\n",
    "tot_cells=0\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    tot_cells+=labels_df['Number'][i]\n",
    "    if np.size(marker)>1:\n",
    "        tot_cells-=labels_df['Number'][i]*(np.size(marker))\n",
    "\n",
    "print('TOT CELLS = ' + str(tot_cells))\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    print('PERC ' + str(labels_df['Condition'][i])  + ' (' + str(marker) + ') = ' + str(100.0*labels_df['Number'][i]/tot_cells) + ' %')\n",
    "\n",
    "print('_'*80)\n",
    "\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    print('MEAN SIZE ' + str(labels_df['Condition'][i])  + ' (' + str(marker) + ') = ' + str(np.mean(list(labels_df['Cell size [um2]'][i]))) + ' um2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of cell positions along X and Y axes\n",
    "fig, axs = plt.subplots(2,1,figsize=(15,10))\n",
    "\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    xcoor= [t[0] for t in list(labels_df['Mean positions [um]'][i])]\n",
    "    ycoor= [t[1] for t in list(labels_df['Mean positions [um]'][i])]\n",
    "    xcount,xbins=np.histogram(xcoor,range=(0,np.shape(im_original)[0]*r_X),bins=30,density=False)\n",
    "    ycount,ybins=np.histogram(ycoor,range=(0,np.shape(im_original)[1]*r_Y),bins=30,density=False)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    if np.size(marker)==1:\n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),color=stain_df.loc[str(labels_df['Condition'][i])]['Color'])\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),color=stain_df.loc[str(labels_df['Condition'][i])]['Color'])\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            rgb_list.append(stain_df.loc[str(labels_df['Condition'][i][k])]['Color'])\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),linestyle='--', color=final_rgb)\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),linestyle='--', color=final_rgb)\n",
    "\n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to Excel file, including all quantification and summary tables\n",
    "with pd.ExcelWriter(Path(tiff_file).stem+'_report.xlsx', engine='xlsxwriter') as writer:\n",
    "    stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "\n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        xlsx_dict={}\n",
    "        if np.size(marker)==1:\n",
    "            for k in range(int(labels_df['Number'][i]-1)):\n",
    "                xlsx_dict[k]=[labels_df['Mean positions [um]'][i][k][0],labels_df['Mean positions [um]'][i][k][1],labels_df['Cell size [um2]'][i][k]]\n",
    "                cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=['X position [um]','Y position [um]','Cell size [um2]'])\n",
    "                cell_df.index+=1\n",
    "        else:\n",
    "            for k in range(int(labels_df['Number'][i]-1)):\n",
    "                xlsx_dict[k]=[item for sublist in [list(labels_df['Shared labels'][i][k]),list(labels_df['Mean positions [um]'][i][k]),labels_df['Cell size [um2]'][i][k]] for item in (sublist if isinstance(sublist, list) else [sublist])]       \n",
    "                cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=[item for sublist in [(labels_df['Marker'][i]),'X position [um]','Y position [um]','Cell size [um2]'] for item in (sublist if isinstance(sublist, list) else [sublist])])\n",
    "                cell_df.index+=1\n",
    "                \n",
    "        cell_df.to_excel(writer, sheet_name=str(marker), index=True)\n",
    "\n",
    "    resume_df=labels_df.drop(columns=['Marker','Shared labels','Mean positions [um]','Cell size [um2]'])\n",
    "    resume_df['%']=100.0*labels_df['Number']/tot_cells\n",
    "    resume_df['Mean size [um2]']=[np.mean(t) for t in list(labels_df['Cell size [um2]'])]\n",
    "    resume_df.loc['TOTAL']=['', tot_cells, '100', np.mean([np.mean(t) for t in list(labels_df['Cell size [um2]'])])]\n",
    "\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
