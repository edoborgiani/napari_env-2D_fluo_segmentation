{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sample data\n",
    "#from skimage.data import cells3d\n",
    "from pathlib import Path\n",
    "#import ndimage\n",
    "\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "import statistics as st\n",
    "import xlsxwriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import pyvista as pv\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import dilation, square\n",
    "from skimage.segmentation import find_boundaries\n",
    "from itertools import combinations\n",
    "\n",
    "from skimage import io, filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import EllipseModel\n",
    "from vispy.color import Colormap\n",
    "from tabulate import tabulate\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.colors import to_rgb, to_hex\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D, Config3D, StarDist3D\n",
    "from stardist.data import test_image_nuclei_2d\n",
    "from stardist.plot import render_label\n",
    "\n",
    "from IPython.display import display_html, clear_output\n",
    "from collections import defaultdict\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "from napari.settings import get_settings\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528e5d3-4be6-4c08-bd1a-521791c65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_trans(im_in,gamma):\n",
    "    val_c = 255.0 / (np.max(im_in)**gamma)\n",
    "    im_out = val_c*(im_in**gamma)\n",
    "    return im_out.copy()\n",
    "\n",
    "def contr_limit(im_in,c_min,c_max):\n",
    "    alpha = 255.0/(c_max - c_min)\n",
    "    beta = - c_min * (alpha)\n",
    "    im_out=(np.clip(alpha*im_in+beta, 0.0, 255.0)).astype(int)\n",
    "    #print(np.max(im_out))\n",
    "    return im_out.copy()\n",
    "    \n",
    "def histo_equal(im_in):\n",
    "    h=im_in.shape[1]\n",
    "    w=im_in.shape[2]\n",
    "    r=im_in.shape[0]\n",
    "\n",
    "    tot_pixs=h*w*r\n",
    "\n",
    "    levels=256\n",
    "\n",
    "    im_hist = np.zeros((levels))\n",
    "\n",
    "    for i in range(0,levels):\n",
    "        im_hist[i] = np.count_nonzero(im_in == i)\n",
    "\n",
    "    pdf = np.zeros((levels))\n",
    "    for i in range(0,levels):\n",
    "        pdf[i] = im_hist[i]/tot_pixs\n",
    "\n",
    "    cdf = np.zeros((levels))\n",
    "    cdf[0] = pdf[0]\n",
    "    for i in range(1, levels):\n",
    "        cdf[i] = pdf[i] + cdf[i-1]\n",
    "\n",
    "    im_out=im_in.copy()\n",
    "        \n",
    "    for u in range(0,r):\n",
    "        for j in range(0,h):\n",
    "            for k in range(0,w):\n",
    "                im_out[u,j,k] = int(round((levels-1) * cdf[im_in[u,j,k]]))\n",
    "    return im_out.copy()\n",
    "\n",
    "def hist_plot(im_in,stain_complete_df,thresh=0):\n",
    "\n",
    "    fig, axs = plt.subplots(1,im_in.shape[2],figsize=(15,2))\n",
    "\n",
    "    for z in range(0,im_in.shape[2]):\n",
    "        hist,bins = np.histogram(im_in[:,:,z].flatten(),256,[0,256])\n",
    "        \n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf* hist.max()/ cdf.max()\n",
    "    \n",
    "        color=stain_complete_df.loc[stain_complete_df.index[z],'Color']\n",
    "    \n",
    "        axs[z].plot(cdf_normalized, color = 'b')\n",
    "        if color=='white':\n",
    "            axs[z].hist(im_in[:,:,z].flatten(),256,[0,256], color = 'gray')\n",
    "        else:\n",
    "            axs[z].hist(im_in[:,:,z].flatten(),256,[0,256], color = color)\n",
    "        axs[z].set_xlim([0,256])\n",
    "        axs[z].legend(('cdf','histogram'), loc = 'upper left')\n",
    "        if thresh>0:\n",
    "            axs[c].plot([thresh,thresh],[0,cdf_normalized.max()],color='g')\n",
    "        axs[z].set_title(stain_complete_df.index[z])\n",
    "        axs[z].set_yscale('log')\n",
    "\n",
    "# Truncate long values for display\n",
    "def truncate_cell(val, width=15):\n",
    "    val_str = str(val)\n",
    "    return val_str if len(val_str) <= width else val_str[:width-3] + \"...\"\n",
    "\n",
    "def merge_touching_labels(label_matrix):\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()  # Nothing to merge\n",
    "\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    touching = defaultdict(set)\n",
    "\n",
    "    # Build adjacency from 8-connected neighbors\n",
    "    for i in range(1, padded.shape[0] - 1):\n",
    "        for j in range(1, padded.shape[1] - 1):\n",
    "            center = padded[i, j]\n",
    "            if center == 0:\n",
    "                continue\n",
    "            # Only consider neighbors, not the center pixel itself\n",
    "            neighborhood = padded[i-1:i+2, j-1:j+2].ravel()\n",
    "            for neighbor in neighborhood:\n",
    "                if neighbor != center and neighbor != 0:\n",
    "                    touching[center].add(neighbor)\n",
    "\n",
    "    # Union-Find setup\n",
    "    all_labels = set(np.unique(label_matrix)) - {0}\n",
    "    parent = {label: label for label in all_labels}\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    # Union all touching labels\n",
    "    for u, neighbors in touching.items():\n",
    "        for v in neighbors:\n",
    "            if u in parent and v in parent:\n",
    "                union(u, v)\n",
    "\n",
    "    # Map each label to its root\n",
    "    label_map = {label: find(label) for label in all_labels}\n",
    "\n",
    "    # Create merged label matrix\n",
    "    merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "    for label, root in label_map.items():\n",
    "        merged[label_matrix == label] = root\n",
    "\n",
    "    # Relabel to sequential labels starting from 1\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "## File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiff_file='PRO_EB-008_2D_M2_5.tif'\n",
    "meta=AICSImage(tiff_file)\n",
    "\n",
    "img = meta.get_image_data(\"XYZ\", T=0) \n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021b76a-2cee-40a6-a26b-f39fcbee5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_X=meta.physical_pixel_sizes.X\n",
    "r_Y=meta.physical_pixel_sizes.Y\n",
    "print([r_X,r_Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "stain_dict={\n",
    "    'MACRO':['F4_80','Red'],\n",
    "    'M2':['CD206','Green'],\n",
    "    'NUCLEI':['DAPI','Blue']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa53135-2a20-4ad4-863d-ede8c2ebf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Color'])\n",
    "stain_df.index.name='Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    im_in=meta.get_image_data(\"XY\", Z=c, C=0, S=0, T=0)\n",
    "    im_in=(im_in/256.0).astype('uint8')\n",
    "    \n",
    "    viewer_0.add_image(im_in, name=stain_df.index[c] + ' (' + c_name + ')', \n",
    "                        colormap=stain_df['Color'][c], blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_setup='PRO_EB-009'\n",
    "use_setup=True\n",
    "# stain_new_df=stain_complete_df.copy()\n",
    "\n",
    "stain_df=stain_df.reset_index(drop=False)\n",
    "stain_complete_df = stain_df.copy()\n",
    "stain_complete_df.set_index(['Condition', 'Marker','Color'], inplace=True)\n",
    "stain_complete_df[['Cont_min','Cont_max','Gamma']]=[0,255,1]\n",
    "\n",
    "if use_setup and os.path.exists(name_setup + '_setup.csv'):\n",
    "    stain_setup_df = pd.read_csv(name_setup + '_setup.csv')\n",
    "    stain_setup_df.set_index(['Condition', 'Marker','Color'], inplace=True)\n",
    "    #print(tabulate(stain_setup_df, headers='keys', tablefmt='grid', showindex=True))\n",
    "    for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "        if stain_complete_df.index[c] in list(stain_setup_df.index.values):\n",
    "            stain_complete_df.loc[stain_complete_df.index[c]]=stain_setup_df.loc[stain_complete_df.index[c]]\n",
    "            # stain_new_df=stain_new_df.drop(stain_complete_df.index[c])\n",
    "        else:\n",
    "            use_setup=False\n",
    "\n",
    "if not(use_setup) or not(os.path.exists(name_setup + '_setup.csv')):\n",
    "\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    \n",
    "    for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "        im_in=meta.get_image_data(\"XY\", Z=c, C=0, S=0, T=0)\n",
    "        im_in=(im_in/256.0).astype('uint8')\n",
    "            \n",
    "        viewer_1.add_image(im_in, name=stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')', \n",
    "                            colormap=stain_complete_df.index[c][2],blending='additive')\n",
    "        \n",
    "    napari.run()\n",
    "    \n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    \n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "        stain_complete_df.loc[stain_complete_df.index[c], 'Cont_min'] =int(contrast_limits[stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')'][0])\n",
    "        stain_complete_df.loc[stain_complete_df.index[c], 'Cont_max'] =int(contrast_limits[stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')'][1])\n",
    "        stain_complete_df.loc[stain_complete_df.index[c], 'Gamma'] =gamma_val[stain_complete_df.index[c][0] + ' (' + stain_complete_df.index[c][1] + ')']\n",
    "\n",
    "    if os.path.exists(name_setup + '_setup.csv'):\n",
    "        stain_setup_df = pd.read_csv(name_setup + '_setup.csv')\n",
    "        stain_setup_df.set_index(['Condition', 'Marker','Color'], inplace=True)\n",
    "        for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "            stain_setup_df.loc[stain_complete_df.index[c]]=stain_complete_df.loc[stain_complete_df.index[c]]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df=stain_csv_setup_df[['Condition','Marker','Color','Cont_min','Cont_max','Gamma']]\n",
    "    stain_csv_setup_df.to_csv(name_setup + '_setup.csv', index=False)\n",
    "\n",
    "stain_df=stain_df.set_index('Condition')\n",
    "stain_complete_df=stain_complete_df.reset_index()\n",
    "stain_complete_df=stain_complete_df.set_index('Condition')\n",
    "stain_complete_df=stain_complete_df.loc[stain_df.index]\n",
    "\n",
    "stain_complete_df=stain_complete_df[['Marker','Color','Cont_min','Cont_max','Gamma']]\n",
    "    \n",
    "#print(tabulate(stain_complete_df, headers='keys', tablefmt='grid', showindex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ba932-3e34-4c20-91a2-8c3cf61d750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "## MULTIPLE TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_in=meta.get_image_data(\"XYZ\", C=0, S=0, T=0)\n",
    "im_in=im_in.copy()\n",
    "im_in=(im_in/256.0).astype('uint8')\n",
    "im_original=im_in.copy()\n",
    "im_out=im_original.copy()\n",
    "im_trans=im_out.copy()\n",
    "\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    im_out[:,:,z]=filters.median(im_in[:,:,z])\n",
    "\n",
    "im_denoised=im_out.copy()\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464bd2-a092-4e4b-a903-a76f22969c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    im_out[:,:,z]=filters.gaussian(im_in[:,:,z],1.0,preserve_range=True)\n",
    "\n",
    "im_filtered=im_out.copy()\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for c, c_name in enumerate (list(stain_complete_df.index)):\n",
    "    im_out[:,:,c]=contr_limit(im_out[:,:,c],stain_complete_df.loc[stain_complete_df.index[c],'Cont_min'],stain_complete_df.loc[stain_complete_df.index[c],'Cont_max'])\n",
    "    im_out[:,:,c]=gamma_trans(im_out[:,:,c],stain_complete_df.loc[stain_complete_df.index[c],'Gamma'])\n",
    "\n",
    "im_trans=im_out.copy()\n",
    "hist_plot(im_out,stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6ca68-af3b-4ca6-8d08-cfe24a5444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding\n",
    "im_in=im_out.copy()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):        \n",
    "    \n",
    "    #Threshold filter\n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    th_filter.SetInsideValue(0)\n",
    "    th_filter.SetOutsideValue(200)\n",
    "    \n",
    "    seg = th_filter.Execute(sitk.GetImageFromArray(im_in[:,:,z]))\n",
    "    \n",
    "    im_out[:,:,z]=sitk.GetArrayFromImage(seg)\n",
    "\n",
    "im_threshold=im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "im_in=im_out.copy()\n",
    "im_out=np.zeros_like(im_in, dtype=np.int32)\n",
    "\n",
    "trig_stardist=False\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    if trig_stardist:\n",
    "        model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "        img_te = normalize(im_trans[:,:,z],1.0,99.8)\n",
    "        im_out[:,:,z], _ = model.predict_instances(img_te)\n",
    "        im_mask=im_in[:,:,z]/np.max(im_in[:,:,z])\n",
    "        im_mask=ndi.binary_erosion(im_mask,structure=np.ones((2,2))).astype(im_mask.dtype)\n",
    "        im_positive=im_out[:,:,z]*(im_mask)\n",
    "        list_positive=list(np.unique(im_positive))\n",
    "        list_positive=list_positive[1:]\n",
    "    else:\n",
    "        distance = ndi.distance_transform_edt(im_in[:,:,z])\n",
    "        coords = peak_local_max(distance, footprint=np.ones((3,3)), labels=im_in[:,:,z].astype(np.int32))\n",
    "        mask = np.zeros(distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndi.label(mask)\n",
    "        transl = watershed(-distance, markers, mask=im_in[:,:,z])\n",
    "        im_out[:,:,z] = transl.copy()  # Ensure integer labels\n",
    "        im_out[:,:,z] = merge_touching_labels(im_out[:,:,z])\n",
    "\n",
    "\n",
    "cm_rand=np.random.rand(int(np.max(im_out)),3)\n",
    "cm_rand[0,:]=[0.0,0.0,0.0]\n",
    "colormaps_rand=Colormap(cm_rand)\n",
    "\n",
    "#im_out=labels.copy()\n",
    "im_segmented=im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_0 = napari.Viewer()\n",
    "\n",
    "for z in range(0,im_in.shape[2]):\n",
    "    viewer_0.add_image(im_original[:,:,z], name='ORIGINAL '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_denoised[:,:,z], name='DENOISED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_filtered[:,:,z], name='FILTERED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_trans[:,:,z], name='CORRECTED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_threshold[:,:,z], name='THRESHOLDED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=stain_complete_df['Color'].iloc[z], blending='additive')\n",
    "    viewer_0.add_image(im_segmented[:,:,z], name='SEGMENTED '+stain_complete_df.index[z] + ' (' + stain_complete_df.loc[stain_complete_df.index[z],'Marker'] + ')', \n",
    "                    colormap=colormaps_rand, blending='additive')\n",
    "\n",
    "viewer_0.scale_bar.visible=True\n",
    "viewer_0.scale_bar.unit='um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "## QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431e1f-94b5-4e66-aef5-accb0297f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_mask = im_segmented > 0\n",
    "labels_dict = {}\n",
    "\n",
    "# Single channel stats\n",
    "for i in range(im_in.shape[2]):\n",
    "    position_list = []\n",
    "    size_list = []\n",
    "    marker = stain_df['Marker'][i]\n",
    "    for n in range(1, int(np.max(im_segmented[:, :, i])) + 1):\n",
    "        y, x = np.where(im_segmented[:, :, i] == n)\n",
    "        mx = np.mean(x * r_X)\n",
    "        my = np.mean(y * r_Y)\n",
    "        position_list.append((mx, my))\n",
    "        size_list.append(np.shape(x)[0] * r_X * r_Y)\n",
    "    labels_dict[stain_complete_df['Marker'].iloc[i]] = [\n",
    "        stain_complete_df.index[i],\n",
    "        stain_complete_df['Color'][i],\n",
    "        int(np.max(im_segmented[:, :, i])),\n",
    "        (),\n",
    "        tuple(position_list),\n",
    "        tuple(size_list)\n",
    "    ]\n",
    "\n",
    "# All combinations of channels (2 or more)\n",
    "layers_n = list(range(im_mask.shape[2]))\n",
    "all_combinations = []\n",
    "for k in range(2, len(layers_n) + 1):\n",
    "    all_combinations.extend(combinations(layers_n, k))\n",
    "\n",
    "for comb in all_combinations:\n",
    "    # Find mask where all channels in comb are positive\n",
    "    shared_mask = np.ones(im_mask.shape[:2], dtype=bool)\n",
    "    for idx in comb:\n",
    "        shared_mask &= im_mask[:, :, idx]\n",
    "    # If no overlap, skip\n",
    "    if not np.any(shared_mask):\n",
    "        continue\n",
    "    # Stack the labels for all channels in the combination\n",
    "    shared_labels = np.stack([im_segmented[:, :, idx][shared_mask] for idx in comb], axis=1)\n",
    "    # Remove background (where any label is zero)\n",
    "    shared_labels = shared_labels[~np.any(shared_labels == 0, axis=1)]\n",
    "    if shared_labels.size == 0:\n",
    "        continue\n",
    "    unique_shared_labels = np.unique(shared_labels, axis=0)\n",
    "\n",
    "    position_list = []\n",
    "    size_list = []\n",
    "    # For each unique label combination, get mean position and size in the first channel of the combination\n",
    "    for n in unique_shared_labels:\n",
    "        y, x = np.where(im_segmented[:, :, comb[0]] == n[0])\n",
    "        mx = np.mean(x * r_X)\n",
    "        my = np.mean(y * r_Y)\n",
    "        position_list.append((mx, my))\n",
    "        size_list.append(np.shape(x)[0] * r_X * r_Y)\n",
    "\n",
    "    # Get marker and condition names for this combination\n",
    "    name_labels = [stain_complete_df['Marker'].iloc[idx] for idx in comb]\n",
    "    name_colors = [stain_complete_df['Color'].iloc[idx] for idx in comb]\n",
    "    name_conditions = [stain_complete_df.index[idx] for idx in comb]\n",
    "    values_labels = [tuple(row) for row in unique_shared_labels]\n",
    "\n",
    "    labels_dict[tuple(name_labels)] = [\n",
    "        name_conditions,\n",
    "        name_colors,\n",
    "        unique_shared_labels.shape[0],\n",
    "        tuple(values_labels),\n",
    "        tuple(position_list),\n",
    "        tuple(size_list)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5021b-f096-45e7-bd06-c5681ac18b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Condition','Color','Number','Shared labels','Mean positions [um]','Cell size [um2]'])\n",
    "labels_df.index.name='Combination'\n",
    "\n",
    "# Make a copy with truncated cell values\n",
    "truncated_df = labels_df.copy()\n",
    "truncated_df[\"Shared labels\"] = truncated_df[\"Shared labels\"].apply(lambda x: truncate_cell(x))\n",
    "truncated_df[\"Mean positions [um]\"] = truncated_df[\"Mean positions [um]\"].apply(lambda x: truncate_cell(x))\n",
    "truncated_df[\"Cell size [um2]\"] = truncated_df[\"Cell size [um2]\"].apply(lambda x: truncate_cell(x))\n",
    "    \n",
    "#print(tabulate(truncated_df, headers='keys', tablefmt='grid', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be760d6e-7466-467a-9270-fb53073765ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db857798-416e-4885-a89e-ec09e95003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cells=0\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    tot_cells+=labels_df['Number'][i]\n",
    "    if np.size(marker)>1:\n",
    "        tot_cells-=labels_df['Number'][i]*(np.size(marker))\n",
    "\n",
    "print('TOT CELLS = ' + str(tot_cells))\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    print('PERC ' + str(labels_df['Condition'][i])  + ' (' + str(marker) + ') = ' + str(100.0*labels_df['Number'][i]/tot_cells) + ' %')\n",
    "\n",
    "print('_'*80)\n",
    "\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    print('MEAN SIZE ' + str(labels_df['Condition'][i])  + ' (' + str(marker) + ') = ' + str(np.mean(list(labels_df['Cell size [um2]'][i]))) + ' um2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(15,10))\n",
    "\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    xcoor= [t[0] for t in list(labels_df['Mean positions [um]'][i])]\n",
    "    ycoor= [t[1] for t in list(labels_df['Mean positions [um]'][i])]\n",
    "    xcount,xbins=np.histogram(xcoor,range=(0,np.shape(im_original)[0]*r_X),bins=30,density=False)\n",
    "    ycount,ybins=np.histogram(ycoor,range=(0,np.shape(im_original)[1]*r_Y),bins=30,density=False)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    if np.size(marker)==1:\n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),color=stain_df.loc[str(labels_df['Condition'][i])]['Color'])\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),color=stain_df.loc[str(labels_df['Condition'][i])]['Color'])\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            rgb_list.append(stain_df.loc[str(labels_df['Condition'][i][k])]['Color'])\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "\n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d02b15-c10b-4b95-8882-ff6769eadbdb",
   "metadata": {},
   "source": [
    "## Evaluate cell size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02a90b-0bb0-46f7-875d-e438714bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "\n",
    "max_size=max([x for t in list(labels_df['Cell size [um2]']) for x in t])\n",
    "\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    sizes= [t for t in list(labels_df['Cell size [um2]'][i])]\n",
    "    if np.size(marker)==1:\n",
    "        axs.hist(sizes,range=(0,max_size),bins=30,label=str(labels_df['Condition'][i]), alpha=1/len(labels_df),color=stain_df.loc[str(labels_df['Condition'][i])]['Color'])\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            rgb_list.append(stain_df.loc[str(labels_df['Condition'][i][k])]['Color'])\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs.hist(sizes,range=(0,max_size),bins=30,label=str(labels_df['Condition'][i]), alpha=1/len(labels_df),color=final_rgb)\n",
    "\n",
    "axs.set_title('NUCLEI SIZE DISTRIBUTION')\n",
    "axs.set_xlabel('[μm2]')\n",
    "axs.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(Path(tiff_file).stem+'_report.xlsx', engine='xlsxwriter') as writer:\n",
    "    stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "\n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        xlsx_dict={}\n",
    "        if np.size(marker)==1:\n",
    "            for k in range(int(labels_df['Number'][i])):\n",
    "                xlsx_dict[k]=[labels_df['Mean positions [um]'][i][k][0],labels_df['Mean positions [um]'][i][k][1],labels_df['Cell size [um2]'][i][k]]\n",
    "                cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=['X position [um]','Y position [um]','Cell size [um2]'])\n",
    "                cell_df.index+=1\n",
    "        else:\n",
    "            for k in range(int(labels_df['Number'][i])):\n",
    "                xlsx_dict[k]=[item for sublist in [list(labels_df['Shared labels'][i][k]),list(labels_df['Mean positions [um]'][i][k]),labels_df['Cell size [um2]'][i][k]] for item in (sublist if isinstance(sublist, list) else [sublist])]       \n",
    "                cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=[item for sublist in [list(labels_df.index[i]),'X position [um]','Y position [um]','Cell size [um2]'] for item in (sublist if isinstance(sublist, list) else [sublist])])\n",
    "                cell_df.index+=1\n",
    "                \n",
    "        cell_df.to_excel(writer, sheet_name=str(marker), index=True)\n",
    "\n",
    "    resume_df=labels_df.drop(columns=['Shared labels','Mean positions [um]','Cell size [um2]'])\n",
    "    resume_df['%']=100.0*labels_df['Number']/tot_cells\n",
    "    resume_df['Mean size [um2]']=[np.mean(t) for t in list(labels_df['Cell size [um2]'])]\n",
    "    resume_df.loc['TOTAL']=['', '', tot_cells, '100', np.mean([np.mean(t) for t in list(labels_df['Cell size [um2]'][:len(stain_df)])])]\n",
    "\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
